{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SEED = 45\n",
    "# Set environment variables for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = 'SEED'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, recall_score, f1_score, confusion_matrix as cm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import MobileNetV2, MobileNet_V2_Weights\n",
    "from torchvision.models.inception import InceptionOutputs\n",
    "from torchvision.models import resnet50,ResNet50_Weights, inception_v3,Inception_V3_Weights,mobilenet_v2,MobileNet_V2_Weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "\n",
    "        # Register hooks to capture gradients and activations\n",
    "        self.hook_handles.append(target_layer.register_forward_hook(self.save_activation))\n",
    "        self.hook_handles.append(target_layer.register_full_backward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def __call__(self, input_tensor, target_category):\n",
    "        self.model.eval()  # Ensure the model is in evaluation mode\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Ensure input_tensor requires gradients\n",
    "        input_tensor.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Target for backprop\n",
    "        target = output[:, target_category].requires_grad_(True)\n",
    "\n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        target.backward(retain_graph=True)\n",
    "\n",
    "        gradients = self.gradients.cpu().data.numpy()[0]\n",
    "        activations = self.activations.cpu().data.numpy()[0]\n",
    "\n",
    "        weights = np.mean(gradients, axis=(1, 2))\n",
    "        cam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cam / np.max(cam)\n",
    "        cam = np.uint8(255 * cam)\n",
    "        cam = cv2.resize(cam, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "        cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "\n",
    "        return cam\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "            \n",
    "# def visualize_images(grad_cam,image_paths, predictions, data_name,transform, title, heatmap_path):\n",
    "def visualize_images(grad_cam,image_paths, predictions,transform, which_grouping,title,which_model):\n",
    "    \n",
    "\n",
    "    if which_model == 'MobileNetV2':\n",
    "        root_path = 'Update path to save images'\n",
    "    elif which_model == 'InceptionNetV3':\n",
    "        root_path = 'Update path  to save images'\n",
    "  \n",
    "    elif which_model == 'ResNet50':\n",
    "        root_path = 'Update path to save images'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Please use 'MobileNetV2', 'InceptionV3', or 'ResNet50'.\")\n",
    "\n",
    "  \n",
    "    misclassified_path = os.path.join(root_path, \"Misclassified_images\")\n",
    "    if not os.path.exists(misclassified_path):\n",
    "        os.makedirs(misclassified_path)\n",
    "\n",
    "    correct_path = os.path.join(root_path, \"Correctly_classifed_images\")\n",
    "    if not os.path.exists(correct_path):\n",
    "        os.makedirs(correct_path)\n",
    "\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # split image path for making heatmap\n",
    "        heatmap_name = image_path.split('/')[-1]\n",
    "        file_split = image_path.split('/')\n",
    "        folder = file_split[-2]\n",
    "        file_name = file_split[-1]\n",
    "\n",
    "        actual_name = image_path.split(\"/\")[-1]\n",
    "\n",
    "     \n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to('cpu')\n",
    "        image_path_display = os.path.join(*image_path.split(os.sep)[-3:])\n",
    "\n",
    "        # Generate GradCAM heatmap\n",
    "        cam = grad_cam(image_tensor, predictions[idx])\n",
    "        # Save the heatmap for verification\n",
    "       # save_to_heatmap_path = os.path.join(heatmap_path, f'{heatmap_name}')\n",
    "        # plt.imshow(cam, cmap='jet')\n",
    "        # plt.axis('off')\n",
    "        # plt.savefig(save_to_heatmap_path, bbox_inches='tight')# uncomment to save heatmap\n",
    "        # plt.close()\n",
    "       \n",
    "\n",
    "        # Convert the original image to a format suitable for OpenCV\n",
    "        # input_image = image_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
    "        input_image = image_tensor.squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "        input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "        input_image = np.uint8(255 * input_image)\n",
    "\n",
    "        # Overlay the heatmap on the original image\n",
    "        overlay = cv2.addWeighted(input_image, 0.5, cam, 0.5, 0)\n",
    "\n",
    "        # Visualize the original image, heatmap, and overlay\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(input_image)\n",
    "        # plt.title('Original Image')\n",
    "\n",
    "        # plt.subplot(1, 3, 2)\n",
    "        # plt.imshow(cam)\n",
    "        # plt.title('GradCAM Heatmap')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(overlay)\n",
    "\n",
    "        plt.suptitle(actual_name)\n",
    "        \n",
    "        # put images in different folders based on its title\n",
    "        if title == 'M':\n",
    "           \n",
    "            # separate erythema and MST groupings into different folders\n",
    "            if 'Erythema' in which_grouping:\n",
    "                # Creaete a subfolder for Erythema grouping\n",
    "                first_subfolder_path = os.path.join(misclassified_path, 'Erythema_groups')\n",
    "                if not os.path.exists(first_subfolder_path):\n",
    "                    os.makedirs(first_subfolder_path)\n",
    "                # Create the subfolder for optical or thermal images within the Erythema grouping\n",
    "                subfolder_path = os.path.join(first_subfolder_path, folder) # folder represent optical/thermal \n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "            \n",
    "            else:\n",
    "                # Create a subfolder for MST grouping\n",
    "                first_subfolder_path = os.path.join(misclassified_path, 'MST_groups')\n",
    "                if not os.path.exists(first_subfolder_path):\n",
    "                    os.makedirs(first_subfolder_path)\n",
    "                # Create the subfolder for optical or thermal images within the MST grouping\n",
    "                subfolder_path = os.path.join(first_subfolder_path, folder)\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "\n",
    "            save_to_file_path = os.path.join( subfolder_path, file_name)  \n",
    "            plt.savefig(save_to_file_path,bbox_inches='tight')\n",
    "\n",
    "        # create a folder for correctly classified images\n",
    "        else:\n",
    "          \n",
    "            # separate erythema and MST groupings into different folders\n",
    "            if 'Erythema' in which_grouping:\n",
    "                # Creaete a subfolder for Erythema grouping\n",
    "                group_subfolder_path = os.path.join(correct_path, 'Erythema_groups')\n",
    "                if not os.path.exists(group_subfolder_path):\n",
    "                    os.makedirs(group_subfolder_path)\n",
    "                # Create the subfolder for optical or thermal images within the Erythema grouping\n",
    "                subfolder_path = os.path.join(group_subfolder_path, folder)\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "            else:\n",
    "                # Create a subfolder for MST grouping\n",
    "                group_subfolder_path = os.path.join(correct_path, 'MST_groups')\n",
    "                if not os.path.exists(group_subfolder_path):\n",
    "                    os.makedirs(group_subfolder_path)\n",
    "                # Create the subfolder for optical or thermal images within the MST grouping\n",
    "                subfolder_path = os.path.join(group_subfolder_path, folder)\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "            \n",
    "            save_to_file_path = os.path.join( subfolder_path, file_name)  \n",
    "            plt.savefig(save_to_file_path,bbox_inches='tight')\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        # plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Visualizing misclassified Monk Skin tones\n",
    "\n",
    "def statistics_by_skin_tone(correctly_classified,correct_preds, misclassified, misclassified_preds,model_name,target_layer, val_transform,modality_name,which_model):\n",
    "     excel_path = r'Update path to file'\n",
    "     subject_skin_tone_file= pd.read_excel(excel_path)\n",
    "\n",
    "     if which_model == 'MobileNetV2':\n",
    "          root_path = '/update path to save images'\n",
    "     elif which_model == 'InceptionNetV3':\n",
    "          root_path = 'Update path to save images'\n",
    "     elif which_model == 'ResNet50':\n",
    "          root_path = 'Update path to save images'\n",
    "     else:\n",
    "          raise ValueError(\"Unsupported model type. Please use 'MobileNetV2', 'InceptionNetV3', or 'ResNet50'.\")\n",
    "\n",
    "     # categorize subjects by monk skin tone number\n",
    "     subject_skin_tone = subject_skin_tone_file[['Subj_ID','Monk_Group']].iloc[:35,:]# replace with test images(extract the hip of test images)\n",
    "     print(len(subject_skin_tone))\n",
    "\n",
    "     # Extract subject_ids\n",
    "     def extract_subject_ids(data): \n",
    "          subj_ids_list = []\n",
    "          for f in data:\n",
    "               file_parts = f.split('/')[-1]\n",
    "               subj_id = file_parts.split('_')[:2]\n",
    "               actual_subj_id = '_'.join(subj_id)\n",
    "               subj_ids_list.append(actual_subj_id)\n",
    "          return subj_ids_list\n",
    "\n",
    "     # test_monk_skin_tone = {}\n",
    "     # misclassified_monk_skin_tone ={}\n",
    "     # group_with_percentage ={}\n",
    "     \n",
    "     def get_skin_tone(data, model_predictions):\n",
    "\n",
    "          skin_tone_cat_dict = {'Light': 0, 'Medium': 0, 'Dark': 0,'Erythema<=5': 0,'Erythema>5': 0}\n",
    "          images_per_cat_dict = { 'Light': [], 'Medium': [], 'Dark': [],'Erythema<=5': [],'Erythema>5': []}\n",
    "          model_pred_per_image_dict = {'Light': [], 'Medium': [], 'Dark': [],'Erythema<=5': [],'Erythema>5': []}\n",
    "\n",
    "          \n",
    "          monk_skin_tone_cat = {}\n",
    "          actual_corre_file = {}\n",
    "          model_pred_per_image = {}\n",
    "\n",
    "\n",
    "          subj_ids = extract_subject_ids(data)\n",
    "          \n",
    "          # Get the Monk Skin tone per subject id\n",
    "          for id, actual_file, model_preds in zip(subj_ids,data, model_predictions):\n",
    "               skintone = subject_skin_tone_file[subject_skin_tone_file['Subj_ID']==id]['Monk_Group'].iloc[0]\n",
    "               if skintone not in monk_skin_tone_cat: \n",
    "                    monk_skin_tone_cat[skintone] = 1\n",
    "                    actual_corre_file [skintone]= []\n",
    "                    actual_corre_file [skintone].append(actual_file)\n",
    "                    model_pred_per_image [skintone]= []\n",
    "                    model_pred_per_image [skintone].append(model_preds)\n",
    "\n",
    "               else:\n",
    "                    monk_skin_tone_cat[skintone] += 1\n",
    "                    actual_corre_file [skintone].append(actual_file)\n",
    "                    model_pred_per_image [skintone].append(model_preds)\n",
    "\n",
    "\n",
    "          #  Categorize  into light, medium and dark\n",
    "          for k, v in monk_skin_tone_cat.items():\n",
    "               # Convert k to integer if it's not already\n",
    "               k_val = int(k) if not isinstance(k, int) else k\n",
    "               \n",
    "               # Check if k is within the ranges, not equal to the range object\n",
    "               if 1 <= k_val <= 3:\n",
    "                    skin_tone_cat_dict['Light'] += v\n",
    "                    images_per_cat_dict['Light'].extend(actual_corre_file[k])\n",
    "                    model_pred_per_image_dict ['Light'].extend(model_pred_per_image[k])\n",
    "\n",
    "               elif 4 <= k_val <= 6:\n",
    "                    skin_tone_cat_dict['Medium'] += v\n",
    "                    images_per_cat_dict['Medium'].extend(actual_corre_file[k])\n",
    "                    model_pred_per_image_dict['Medium'].extend(model_pred_per_image[k])\n",
    "               else:\n",
    "                    skin_tone_cat_dict['Dark'] += v\n",
    "                    images_per_cat_dict['Dark'].extend(actual_corre_file[k])\n",
    "                    model_pred_per_image_dict['Dark'].extend(model_pred_per_image[k])\n",
    "\n",
    "               # Categorize based on Erythema groupings (<=5,>=6)\n",
    "               if k <= 5:\n",
    "                   skin_tone_cat_dict['Erythema<=5'] += v\n",
    "                   images_per_cat_dict['Erythema<=5'].extend(actual_corre_file[k])\n",
    "                   model_pred_per_image_dict['Erythema<=5'].extend(model_pred_per_image[k])\n",
    "\n",
    "               else:\n",
    "                   skin_tone_cat_dict['Erythema>5'] += v\n",
    "                   images_per_cat_dict['Erythema>5'].extend(actual_corre_file[k])\n",
    "                   model_pred_per_image_dict['Erythema>5'].extend(model_pred_per_image[k])\n",
    "\n",
    "                 \n",
    "          return skin_tone_cat_dict, images_per_cat_dict, model_pred_per_image_dict\n",
    "     \n",
    "     misclassified_skin_cat, misclass_images_per_cat,misclassified_pred_per_cat = get_skin_tone(misclassified,misclassified_preds)\n",
    "     correctly_classified_skin_cat,correct_images_per_cat, correct_pred_per_cat  = get_skin_tone(correctly_classified,correct_preds)\n",
    "     \n",
    "     ## Initialize empty dictionaries for the modified data\n",
    "     misclass_images_per_cat_modified_dict = {}\n",
    "     correct_images_per_cat_modified_dict = {}\n",
    "\n",
    "     # Process misclassified images\n",
    "     print(f\"Misclassified skin tone categories: {misclassified_skin_cat}\")\n",
    "     print('%' * 50)\n",
    "     for k, v in misclass_images_per_cat.items():\n",
    "     # Create a new list for each category\n",
    "          misclass_images_per_cat_modified_list = []\n",
    "          print(f\"Misclassified category: {k}\")\n",
    "          for img in v:\n",
    "               # Get the file name\n",
    "               name = img.split('/')[-1]\n",
    "               misclass_images_per_cat_modified_list.append(name)\n",
    "               print(name)\n",
    "          # Assign the category-specific list to the dictionary\n",
    "          misclass_images_per_cat_modified_dict[k] = misclass_images_per_cat_modified_list\n",
    "\n",
    "     # Process correctly classified images\n",
    "     print('%' * 50)\n",
    "     print(f\"Correctly classified skin tone categories: {correctly_classified_skin_cat}\")\n",
    "     for k, v in correct_images_per_cat.items():\n",
    "          # Create a new list for each category\n",
    "          correct_images_per_cat_modified_list = []\n",
    "          print(f\"Correctly classified category: {k}\")\n",
    "          for img in v:\n",
    "               # Get the file name\n",
    "               name = img.split('/')[-1]\n",
    "               correct_images_per_cat_modified_list.append(name)\n",
    "               print(name)\n",
    "          # Assign the category-specific list to the dictionary\n",
    "          correct_images_per_cat_modified_dict[k] = correct_images_per_cat_modified_list\n",
    "     \n",
    "     \n",
    "     # Process misclassified images and save each category to its own CSV\n",
    "     for category, image_list in misclass_images_per_cat_modified_dict.items():\n",
    "          # Create a DataFrame with just this category's images\n",
    "          df = pd.DataFrame({\n",
    "               f'{category}': image_list\n",
    "          })\n",
    "          \n",
    "          # Create a filename for this category\n",
    "          save_path = os.path.join(root_path, f\"{modality_name}_misclass_{category}_images.csv\")\n",
    "          \n",
    "          # Save to CSV\n",
    "          df.to_csv(save_path, index=False)\n",
    "          print(f\"Saved {category} misclassified images to: {save_path}\")\n",
    "\n",
    "     # Process correctly classified images and save each category to its own CSV\n",
    "     for category, image_list in correct_images_per_cat_modified_dict.items():\n",
    "          # Create a DataFrame with just this category's images\n",
    "          df = pd.DataFrame({\n",
    "               f'{category}': image_list\n",
    "          })\n",
    "          \n",
    "          # Create a filename for this category\n",
    "          save_path = os.path.join(root_path, f\"{modality_name}_correct_{category}_images.csv\")\n",
    "          \n",
    "          # Save to CSV\n",
    "          df.to_csv(save_path, index=False)\n",
    "          print(f\"Saved {category} correctly classified images to: {save_path}\")\n",
    "\n",
    "    # Visualize  misclassified image  and correctly_classified image in each category using GRADCAM\n",
    "\n",
    "\n",
    "     grad_cam = GradCAM(model_name, target_layer)\n",
    "\n",
    "     for k,v in correct_images_per_cat.items():\n",
    "   \n",
    "          correct_images = v\n",
    "          correct_pred = correct_pred_per_cat[k]\n",
    "\n",
    "          visualize_images(grad_cam, correct_images, correct_pred,val_transform,k, title=f\"C\", which_model= which_model)\n",
    "\n",
    "     for k,v in misclass_images_per_cat.items():\n",
    "\n",
    "          misclass_images = v\n",
    "          misclassified_pred = misclassified_pred_per_cat[k] \n",
    "\n",
    "          visualize_images(grad_cam, misclass_images, misclassified_pred,val_transform,k, title=f\"M\", which_model= which_model)\n",
    "     \n",
    "     \n",
    "\n",
    "global erythema_optical_path\n",
    "global erythema_thermal_bw_path\n",
    "global erythema_thermal_color_path\n",
    "global monk_filepath\n",
    "\n",
    "#get erythema images\n",
    "excel_path = r'Update path to excel file'\n",
    "erythema_file= pd.read_excel(excel_path)\n",
    "erythema_path = r'Update path to erythema images'\n",
    "\n",
    "erythema_optical_path = f'{erythema_path}only_cupping_images_optical'\n",
    "erythema_thermal_bw_path = f'{erythema_path}only_cupping_images'\n",
    "erythema_thermal_color_path = f'{erythema_path}only_cupping_images_color'\n",
    "\n",
    "# Monk skin tone groupings\n",
    "monk_filepath =r'Update path to file'\n",
    "\n",
    "\n",
    "\n",
    "#  Load images for each modality\n",
    "def get_valid_images(image_dir):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "   \n",
    "    image_names = erythema_file['Img Name'].values\n",
    "    labels = erythema_file['Label'].values\n",
    "    for img_name, label in zip(image_names, labels):\n",
    "        img_name = img_name.strip()  # Remove any leading/trailing whitespace\n",
    "        image_path = os.path.join(image_dir, img_name)\n",
    "        file_parts = img_name.split('_')\n",
    "      \n",
    "        if os.path.exists(image_path):\n",
    "            train_images.append(image_path)\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: Image not found: {image_path}\")\n",
    "    print(f'Total number of train images and train labels are:', len(train_images),len(train_labels))\n",
    "\n",
    "    return  train_images,train_labels\n",
    "\n",
    "\n",
    "\n",
    "def get_fold_train_test(data,labels,test_subjects):\n",
    "\n",
    "    # initialize list for optical train and test folds\n",
    "    train_fold= []\n",
    "    test_fold= []\n",
    "    train_fold_labels = []\n",
    "    test_fold_labels = []\n",
    "\n",
    "\n",
    "    data_label_dict = dict(zip(data, labels))\n",
    "    #  get optical train and test paths \n",
    "\n",
    "    for file in data:\n",
    "        \n",
    "        file_parts = file.split('/')[-1]\n",
    "        subj_id = '_'.join(file_parts.split('_')[:2])\n",
    "       \n",
    "        if subj_id not in test_subjects:\n",
    "            train_fold.append(file)\n",
    "            train_fold_labels.append( data_label_dict[file])\n",
    "        else:\n",
    "            test_fold.append(file)\n",
    "            test_fold_labels.append( data_label_dict[file])\n",
    "    \n",
    "    return train_fold,train_fold_labels,test_fold,test_fold_labels\n",
    "\n",
    "# Stratified k-fold cv for folds\n",
    "def stratified_kfold():  \n",
    "  \n",
    "    optical_ery_folds = []\n",
    "    thermal_bw_ery_folds = []\n",
    "    thermal_color_ery_folds = []\n",
    "\n",
    "    # Get the images and labels per modality\n",
    "    optical_ery,optical_ery_labels= get_valid_images(erythema_optical_path)\n",
    "    # get data for thermal bw images\n",
    "    thermal_bw_ery,thermal_bw_ery_labels= get_valid_images(erythema_thermal_bw_path)\n",
    "    # get data for thermal color images\n",
    "    thermal_color_ery,thermal_color_ery_labels = get_valid_images(erythema_thermal_color_path)\n",
    "\n",
    "\n",
    "    # Get stratified k-fold using the subject id for grouping\n",
    "    sub_monk_skin_tone = pd.read_excel(monk_filepath).iloc[0:35,:]\n",
    "\n",
    "    subject_ids = sub_monk_skin_tone['Subj_ID']\n",
    "    monk_scores = sub_monk_skin_tone['Monk_Group']\n",
    "\n",
    "    # Initialize StratifiedGroupKFold\n",
    "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(sgkf.split(subject_ids, \n",
    "                                                            monk_scores, \n",
    "                                                            groups=subject_ids)):\n",
    "      \n",
    "        test_subjects = subject_ids[test_idx].to_list()\n",
    "        print(test_subjects )\n",
    "       \n",
    "\n",
    "        train_fold_optical_ery,train_fold_optical_ery_labels,test_fold_optical_ery,test_fold_optical_ery_labels= get_fold_train_test(optical_ery,optical_ery_labels,test_subjects)\n",
    "        train_fold_thermal_bw_ery,train_fold_thermal_bw_ery_labels,test_fold_thermal_bw_ery,test_fold_thermal_bw_ery_labels= get_fold_train_test(thermal_bw_ery,thermal_bw_ery_labels,test_subjects)\n",
    "        train_fold_thermal_color_ery,train_fold_thermal_color_ery_labels,test_fold_thermal_color_ery,test_fold_thermal_color_ery_labels= get_fold_train_test(thermal_color_ery,thermal_color_ery_labels,test_subjects)\n",
    "        \n",
    "        optical_ery_folds.append({'train_images': train_fold_optical_ery, \n",
    "                                'train_labels':train_fold_optical_ery_labels, \n",
    "                                'test_images': test_fold_optical_ery, \n",
    "                                'test_labels':test_fold_optical_ery_labels})\n",
    "        \n",
    "        thermal_bw_ery_folds.append({'train_images': train_fold_thermal_bw_ery, \n",
    "                                'train_labels':train_fold_thermal_bw_ery_labels,\n",
    "                                    'test_images': test_fold_thermal_bw_ery, \n",
    "                                    'test_labels':test_fold_thermal_bw_ery_labels})\n",
    "        \n",
    "        thermal_color_ery_folds.append({'train_images': train_fold_thermal_color_ery, \n",
    "                                    'train_labels': train_fold_thermal_color_ery_labels,\n",
    "                                    'test_images': test_fold_thermal_color_ery, \n",
    "                                    'test_labels':test_fold_thermal_color_ery_labels})\n",
    "        \n",
    "        print(f'Fold {fold_idx+1} extracted')\n",
    "    return optical_ery_folds,thermal_bw_ery_folds, thermal_color_ery_folds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def model_train_evaluation(data_in_folds,name):\n",
    "\n",
    "\n",
    "def model_train_evaluation(data_in_folds,name,model_config,img_size,which_model):\n",
    "    print(f'Image size is {img_size}')\n",
    "\n",
    "\n",
    "    global data_name\n",
    "    batch_size = 32\n",
    "    image_size =img_size\n",
    "   \n",
    "    # model = MobileNetV2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "    # model= mobilenet_v2(weights = MobileNet_V2_Weights.DEFAULT)\n",
    "    # which_model = 'MobileNetV2'\n",
    "    model =  model_config\n",
    "\n",
    "    data_name = name    \n",
    "    model_accuracy = []\n",
    "    model_auc = []\n",
    "    model_specificity = []\n",
    "    model_sensitivity = []\n",
    "    model_f1 = []\n",
    "    total_predicted_labels = []\n",
    "    total_true_labels = []\n",
    "    # best_overall_acc = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    best_models = {}\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, image_paths, labels, transform=None):\n",
    "            self.image_paths = image_paths\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "            self.label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image_path = self.image_paths[idx]\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            label_idx = self.label_map[label]\n",
    "            return image, torch.tensor(label_idx, dtype=torch.long)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float32),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float32),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    def visualize_augmentations(dataset, num_samples=3, img_indices=None):\n",
    "    # def visualize_individual_augmentations(dataset, img_indices=None, num_samples=5):\n",
    "        \"\"\"\n",
    "        Visualize augmentations applied to training images, with each image displayed individually\n",
    "        \n",
    "        Parameters:\n",
    "            dataset: Your CustomDataset instance\n",
    "            img_indices: Specific image indices to visualize (optional)\n",
    "            num_samples: Number of random samples to visualize if img_indices not provided\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # If no specific indices provided, select random ones\n",
    "        if img_indices is None:\n",
    "            img_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "        \n",
    "        # Original transform components (for individual augmentations)\n",
    "        resize = transforms.Resize(image_size)\n",
    "        rotate = transforms.RandomRotation(20)\n",
    "        h_flip = transforms.RandomHorizontalFlip(p=1.0)  # Always flip\n",
    "        v_flip = transforms.RandomVerticalFlip(p=1.0)    # Always flip\n",
    "        \n",
    "        figures = []\n",
    "        \n",
    "        # Process each selected image\n",
    "        for idx in img_indices:\n",
    "            # Get the image path and label\n",
    "            image_path = dataset.image_paths[idx]\n",
    "            label = dataset.labels[idx]\n",
    "            \n",
    "            # Create a figure for this specific image\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            \n",
    "            # Load original image\n",
    "            original_img = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Apply individual transformations\n",
    "            resized_img = resize(original_img)\n",
    "            rotated_img = rotate(resized_img.copy())\n",
    "            h_flipped_img = h_flip(resized_img.copy())\n",
    "            v_flipped_img = v_flip(resized_img.copy())\n",
    "            \n",
    "            # Display images\n",
    "            axes[0].imshow(resized_img)\n",
    "            axes[0].set_title(f'Original Image')\n",
    "            \n",
    "            axes[1].imshow(rotated_img)\n",
    "            axes[1].set_title('Rotation at 20 degrees')\n",
    "            \n",
    "            axes[2].imshow(h_flipped_img)\n",
    "            axes[2].set_title('Horizontal Flip')\n",
    "            \n",
    "            axes[3].imshow(v_flipped_img)\n",
    "            axes[3].set_title('Vertical Flip')\n",
    "            \n",
    "            # Remove axis ticks\n",
    "            for ax in axes:\n",
    "                ax.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            # fig.suptitle(f'Augmentations for Image {idx}', fontsize=16, y=1.05)\n",
    "            plt.show()\n",
    "            \n",
    "            figures.append(fig)\n",
    "        \n",
    "        return figures\n",
    "\n",
    "    # Run model on each fold\n",
    "    print(f\"Model training and evaluation on {name} modality\")\n",
    "\n",
    "    total_correctly_classified =[]\n",
    "    total_correct_labels =[]\n",
    "    total_correct_preds = []\n",
    "    total_misclassified = []\n",
    "    total_misclass_labels = []\n",
    "    total_misclass_pred = []\n",
    "\n",
    "    all_true_labels_across_folds = []\n",
    "    all_pred_labels_across_folds = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for fold_idx, fold in enumerate(data_in_folds):\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f'Starting Fold {fold_idx+1}')\n",
    "        print(\"=\"*50)\n",
    "        print(fold.keys())\n",
    "\n",
    "        fold_train_paths = fold['train_images']\n",
    "        fold_train_labels = fold['train_labels']\n",
    "        fold_val_paths = fold['test_images']\n",
    "        fold_val_labels = fold['test_labels']\n",
    "\n",
    "        # Print the total training and evaluation images\n",
    "        print(f'Total training images and labels are:', len(fold_train_paths), len(fold_train_labels))\n",
    "        print(f'Total evaluation images and labels are:', len(fold_val_paths), len(fold_val_labels))\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = CustomDataset(fold_train_paths, fold_train_labels, transform=train_transform)\n",
    "        val_dataset = CustomDataset(fold_val_paths, fold_val_labels, transform=val_transform)\n",
    "\n",
    "        # Define seed worker function (moved outside the loop but called here)\n",
    "        def seed_worker(worker_id):\n",
    "            worker_seed = SEED\n",
    "            np.random.seed(worker_seed)\n",
    "            random.seed(worker_seed)\n",
    "\n",
    "        # Create a generator with fixed seed\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(SEED)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g\n",
    "        )\n",
    "\n",
    "        # Initialize a completely new model for each fold\n",
    "        if which_model == 'MobileNetV2':\n",
    "            # Create a fresh instance of the model\n",
    "            if 'mobilenet_v2' in globals():\n",
    "                # If function is available directly\n",
    "                model_name = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "            else:\n",
    "                # Fallback to class-based initialization\n",
    "                model_name = MobileNetV2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "            \n",
    "            # Reset seed before modifying the model\n",
    "            torch.manual_seed(SEED)\n",
    "            model_name.classifier[1] = torch.nn.Linear(model_name.classifier[1].in_features, len(set(fold_train_labels)))\n",
    "            \n",
    "            # Define initialization function\n",
    "            def init_weights(m):\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "            # Apply initialization\n",
    "            model_name.classifier[1].apply(init_weights)\n",
    "            print(f'Test labels are ', len(set(fold_train_labels)))\n",
    "        \n",
    "        elif which_model == 'InceptionNetV3':\n",
    "            # Create a fresh instance of the model\n",
    "            model_name = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "            \n",
    "            # Reset seed before modifying the model\n",
    "            torch.manual_seed(SEED)\n",
    "            model_name.fc = nn.Linear(model_name.fc.in_features, len(set(fold_train_labels)))\n",
    "            \n",
    "            # Define initialization function (if not defined outside)\n",
    "            def init_weights(m):\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "            # Apply initialization\n",
    "            model_name.fc.apply(init_weights)\n",
    "        \n",
    "        else:  # ResNet50\n",
    "            # Create a fresh instance of the model\n",
    "            model_name = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            \n",
    "            # Reset seed before modifying the model\n",
    "            torch.manual_seed(SEED)\n",
    "            model_name.fc = nn.Linear(model_name.fc.in_features, len(set(fold_train_labels)))\n",
    "            \n",
    "            # Define initialization function (if not defined outside)\n",
    "            def init_weights(m):\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "            # Apply initialization\n",
    "            model_name.fc.apply(init_weights)\n",
    "        \n",
    "        # Move model to device\n",
    "        model_name.to(device)\n",
    "\n",
    "        # Define criterion and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model_name.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "        \n",
    "        best_val_auc = 0.0\n",
    "        patience = 20\n",
    "        epochs_no_improve = 0\n",
    "        num_epochs = 100\n",
    "        # Lists to track training and validation losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Rest of your training and validation code continues...\n",
    "        #     # Initialize the model\n",
    "        #     if which_model =='MobileNetV2':\n",
    "        #         model_name = model\n",
    "        #         model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(set(fold_train_labels)))\n",
    "                \n",
    "        #         model_name.to(device)\n",
    "        #         print(f'Test labels are ', len(set(fold_train_labels)))\n",
    "\n",
    "        #     else:\n",
    "        #         model_name = model\n",
    "        #         model_name.fc = nn.Linear(model_name.fc.in_features, len(set(fold_train_labels)))\n",
    "        #         model_name.to(device)\n",
    "        #         print(f'Test labels are ', len(set(fold_train_labels)))\n",
    "\n",
    "        print('Starting training loop')\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # Training phase\n",
    "            model_name.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for data in train_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_name(inputs)\n",
    "                \n",
    "                if isinstance(outputs, InceptionOutputs):\n",
    "                    logits = outputs.logits\n",
    "                    aux_logits = outputs.aux_logits\n",
    "                    loss = criterion(logits, targets) + 0.4 * criterion(aux_logits, targets)  # Add auxiliary loss\n",
    "                else:\n",
    "                    logits = outputs\n",
    "                    loss = criterion(logits, targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            \n",
    "            # Validation phase\n",
    "            model_name.eval()\n",
    "            val_corrects = 0\n",
    "            val_total = 0\n",
    "            val_all_labels = []\n",
    "            val_all_probs = []\n",
    "            val_all_preds = []\n",
    "            val_running_loss = 0.0\n",
    "\n",
    "            correctly_classified = []\n",
    "            correct_labels = []\n",
    "            correct_preds = []\n",
    "            misclassified = []\n",
    "            misclass_labels = []\n",
    "            misclass_preds = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, (inputs, targets) in enumerate(val_loader):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model_name(inputs)\n",
    "                    \n",
    "                    # Handle output for InceptionNetV3 and ResNet50\n",
    "                    if which_model == 'InceptionNetV3' and isinstance(outputs, InceptionOutputs):\n",
    "                        logits = outputs.logits  # Use logits for classification\n",
    "                    else:\n",
    "                        logits = outputs  # For ResNet50 and MobileNet, output is already logits\n",
    "                    \n",
    "                    # Calculate validation loss\n",
    "                    val_loss = criterion(logits, targets)\n",
    "                    val_running_loss += val_loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    \n",
    "                    # Track image paths for analyzing errors\n",
    "                    start_idx = i * val_loader.batch_size\n",
    "                    for j in range(len(preds)):\n",
    "                        if start_idx + j < len(fold_val_paths):  # Ensure index is in range\n",
    "                            image_path = fold_val_paths[start_idx + j]\n",
    "                            label = targets[j].item()\n",
    "                            pred = preds[j].item()\n",
    "                            if pred == label:\n",
    "                                correctly_classified.append(image_path)\n",
    "                                correct_labels.append(label)\n",
    "                                correct_preds.append(pred)\n",
    "                            else:\n",
    "                                misclassified.append(image_path)\n",
    "                                misclass_labels.append(label)\n",
    "                                misclass_preds.append(pred)\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    val_total += targets.size(0)\n",
    "                    val_corrects += (preds == targets).sum().item()\n",
    "                    val_all_labels.extend(targets.cpu().numpy())\n",
    "                    val_all_probs.extend(torch.softmax(logits, dim=1)[:, 1].cpu().numpy())\n",
    "                    val_all_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "            # Calculate epoch validation loss\n",
    "            epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            # scheduler.step(epoch_val_loss)\n",
    "            \n",
    "            # Compute metrics\n",
    "            val_acc = val_corrects / val_total\n",
    "            val_auc = roc_auc_score(val_all_labels, val_all_probs)\n",
    "            sensitivity = recall_score(val_all_labels, val_all_preds, pos_label=1)\n",
    "            tn,fp,fn,tp = cm(val_all_labels, val_all_preds, labels= [0,1]).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            f1 = f1_score(val_all_labels, val_all_preds,pos_label=1)\n",
    "\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch}/{num_epochs}, \"\n",
    "                f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "                f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "                f\"Val Acc: {val_acc:.3f}, \"\n",
    "                f\"AUC: {val_auc:.3f}, \"\n",
    "                f\"Sens: {sensitivity:.3f}, \"\n",
    "                f\"Spec: {specificity:.3f}, \"\n",
    "                f\"F1: {f1:.3f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # Update all_predictions and all_labels for saving later\n",
    "            all_predictions.extend(val_all_preds)\n",
    "            all_labels.extend(val_all_labels)\n",
    "\n",
    "            # modification done on Februray 26th,2025\n",
    "    \n",
    "            # Save the best model for this fold\n",
    "                # Check and update the best model for this fold\n",
    "            if val_auc > best_val_auc:\n",
    "                best_val_auc= val_auc\n",
    "                epochs_no_improve = 0\n",
    "                best_model_state = model_name.state_dict()  # Save the state dict of the best model for this fold\n",
    "                best_val_metrics = {\n",
    "                        'val_acc': val_acc,\n",
    "                        'val_auc': val_auc,\n",
    "                        'sensitivity': sensitivity,\n",
    "                        'specificity': specificity,\n",
    "                        'f1': f1\n",
    "                    } \n",
    "                temp_correctly_classified = correctly_classified\n",
    "                temp_correct_labels = correct_labels\n",
    "                temp_correct_preds = correct_preds\n",
    "                temp_misclassified = misclassified\n",
    "                temp_misclass_labels = misclass_labels\n",
    "                temp_misclass_pred = misclass_preds\n",
    "                temp_val_all_labels = val_all_labels\n",
    "                temp_val_all_preds = val_all_preds\n",
    "                \n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f'No performance gains at:  {epochs_no_improve}')\n",
    "            # Early stopping\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'Early stopping at epoch {epoch} for fold {fold_idx + 1}')\n",
    "                break\n",
    "        \n",
    "\n",
    "        # Plot training and validation loss\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "        # plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "        # plt.xlabel('Epochs')\n",
    "        # plt.ylabel('Loss')\n",
    "        # plt.title(f'Training and Validation Loss - {name} Fold {fold_idx + 1}')\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        \n",
    "        # Define the save directory based on model type\n",
    "        if which_model == 'MobileNetV2':\n",
    "            save_dir = 'Update path'\n",
    "        elif which_model == 'InceptionNetV3':\n",
    "            save_dir = 'Update path'\n",
    "        else:  # ResNet50\n",
    "            save_dir = 'Update path'\n",
    "            \n",
    "        # Ensure directory exists\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Save loss plot\n",
    "        # plt.savefig(f'{save_dir}{name}_{which_model}_fold_{fold_idx+1}_loss_plot.png')\n",
    "        # plt.show()\n",
    "\n",
    "        # Update model_accuracy, model_auc, model_specificity, model_sensitivity, and model_f1\n",
    "        model_accuracy.append(best_val_metrics['val_acc'])\n",
    "        model_auc.append(best_val_metrics['val_auc'])\n",
    "        model_specificity.append(best_val_metrics['specificity'])\n",
    "        model_sensitivity.append(best_val_metrics['sensitivity'])\n",
    "        model_f1.append(best_val_metrics['f1'])\n",
    "\n",
    "\n",
    "            # best_auc_across_folds.append(f'{model_auc:.3f}')\n",
    "\n",
    "        total_correctly_classified.extend(temp_correctly_classified)\n",
    "        total_misclassified.extend(temp_misclassified)\n",
    "\n",
    "        total_correct_preds.extend(temp_correct_preds)\n",
    "        total_misclass_pred.extend(temp_misclass_pred)\n",
    "\n",
    "        total_correct_labels.extend(temp_correct_labels)\n",
    "        total_misclass_labels.extend(temp_misclass_labels)\n",
    "\n",
    "        all_true_labels_across_folds.extend(temp_val_all_labels)\n",
    "        all_pred_labels_across_folds.extend(temp_val_all_preds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get the mean and standard deviation of evaluation metrics\n",
    "    model_accuracy_mean = np.mean(model_accuracy)\n",
    "    model_accuracy_std = np.std(model_accuracy)\n",
    "    model_auc_mean = np.mean(model_auc)\n",
    "    model_auc_std = np.std(model_auc)\n",
    "    model_specificity_mean = np.mean(model_specificity)\n",
    "    model_specificity_std = np.std(model_specificity)\n",
    "    model_sensitivity_mean = np.mean(model_sensitivity)\n",
    "    model_sensitivity_std = np.std(model_sensitivity)\n",
    "    model_f1_mean = np.mean(model_f1)\n",
    "    model_f1_std = np.std(model_f1)\n",
    "\n",
    "    #print metrics: mean and std\n",
    "    print(f'Mean and standard deviation of evaluation metrics for {which_model}{name}:')\n",
    "    print(f'Accuracy: {model_accuracy_mean:.3f} {model_accuracy_std:.3f}')\n",
    "    print(f'AUC: {model_auc_mean:.3f}  {model_auc_std:.3f}')\n",
    "    print(f'Sensitivity: {model_sensitivity_mean:.3f}  {model_sensitivity_std:.3f}')\n",
    "    print(f'Specificity: {model_specificity_mean:.3f}  {model_specificity_std:.3f}')\n",
    "    print(f'F1: {model_f1_mean:.3f}  {model_f1_std:.3f}')\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # print(f'Correctly classified labels: {best_classification_outcomes[\"correctly_classified_labels\"]}')\n",
    "    # print(f'Misclassified labels: {best_classification_outcomes[\"misclassified_labels\"]}')\n",
    "\n",
    "\n",
    "    # Show the list of top aucs per fold\n",
    "    print(f'Best AUCs across all folds for {name}: {model_auc}')\n",
    "    # Confusion matrix across 5-folds \n",
    "\n",
    "    # all_val_true_labels =  classification_outcomes[\"true_labels\"]\n",
    "    # all_val_predicted_labels = classification_outcomes[\"predicted_labels\"]\n",
    "    # all_val_true_labels = all_labels\n",
    "    # all_val_predicted_labels = all_predictions\n",
    "    # Create confusion matrix display\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    all_true_labels_across_folds, \n",
    "    all_pred_labels_across_folds, \n",
    "    display_labels=['No Erythema','Erythema'],\n",
    "    cmap='YlGnBu'\n",
    ")\n",
    "\n",
    "   # Access the axis object and set font sizes\n",
    "    ax = disp.ax_\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=12)  # For y-axis labels\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=12)  # For x-axis labels\n",
    "    # modify the fontsize of the x and y axes\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=15)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=15)\n",
    "\n",
    "    # To adjust the numbers inside the cells\n",
    "    for im in ax.images:\n",
    "        im.colorbar.ax.tick_params(labelsize=16)  # For colorbar text\n",
    "        \n",
    "        # Adjust only the numbers inside the cells\n",
    "        for text in disp.ax_.texts:\n",
    "            text.set_fontsize(18)  \n",
    "\n",
    "    # Define the save directory based on model type\n",
    "    if which_model == 'MobileNetV2':\n",
    "        save_dir = 'update path'\n",
    "    elif which_model == 'InceptionNetV3':\n",
    "        save_dir = '/update path'\n",
    "    else:  # ResNet50\n",
    "        save_dir = ''\n",
    "        \n",
    "    # Ensure directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.title(f'{name} {which_model} Confusion Matrix')\n",
    "    plt.savefig(f'{save_dir}{name}_{which_model}_confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "     # Save the metrics to file\n",
    "    output_path = os.path.join(save_dir, f'{name}_{which_model}_metrics.txt')\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(f'Mean and standard deviation of evaluation metrics for {which_model}{name}:\\n')\n",
    "        f.write(f'Accuracy: {model_accuracy_mean:.3f} {model_accuracy_std:.3f}\\n')\n",
    "        f.write(f'AUC: {model_auc_mean:.3f}  {model_auc_std:.3f}\\n')\n",
    "        f.write(f'Sensitivity: {model_sensitivity_mean:.3f}  {model_sensitivity_std:.3f}\\n')\n",
    "        f.write(f'Specificity: {model_specificity_mean:.3f}  {model_specificity_std:.3f}\\n')\n",
    "        f.write(f'F1: {model_f1_mean:.3f}  {model_f1_std:.3f}\\n')\n",
    "\n",
    "\n",
    "    # GRADCAM analysis for all models\n",
    "    # Define model-specific target layers for GradCAM\n",
    "    if which_model == 'MobileNetV2':\n",
    "        target_layer = model_name.features[-1]\n",
    "    elif which_model == 'InceptionNetV3':\n",
    "        target_layer = model_name.Mixed_7c\n",
    "    else:  # ResNet50\n",
    "        target_layer = model_name.layer4[-1]\n",
    "        \n",
    "    validation_transform = val_transform\n",
    "    \n",
    "   \n",
    "    # Make sure to pass which_model to the statistics_by_skin_tone function\n",
    "    statistics_by_skin_tone(\n",
    "        total_correctly_classified, \n",
    "        total_correct_preds, \n",
    "        total_misclassified, \n",
    "        total_misclass_pred, \n",
    "        model_name, \n",
    "        target_layer, \n",
    "        validation_transform, \n",
    "        name,\n",
    "        which_model=which_model  # Pass the model type to save in correct directory\n",
    "    )\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error saving predictions: {e}\")\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "# Calling model training and evaluation\n",
    "\n",
    "optical_ery_folds,thermal_bw_ery_folds, thermal_color_ery_folds= stratified_kfold()\n",
    "# Define your models and datasets\n",
    "models = ['MobileNetV2', 'InceptionNetV3', 'ResNet50']\n",
    "# models = ['InceptionNetV3', 'ResNet50']\n",
    "# models = ['MobileNetV2']\n",
    "\n",
    "datasets = [\n",
    "    {'train_images': optical_ery_folds, 'name': 'Optical Erythema'},\n",
    "    {'train_images': thermal_color_ery_folds, 'name': 'Thermal Color Erythema'}\n",
    "]\n",
    "\n",
    "# Get the k-fold data\n",
    "optical_ery_folds, thermal_bw_ery_folds, thermal_color_ery_folds = stratified_kfold()\n",
    "\n",
    "# Run each model-modality combination with fresh random states\n",
    "for model_a in models:\n",
    "    for dataset in datasets:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Training with patience of 20 + weight decay of 0.0005\".upper())\n",
    "        print(f\"\\nSTARTING NEW RUN: {model_a} on {dataset['name']}\")\n",
    "\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Reset ALL random states before each model-dataset combination\n",
    "        random.seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(SEED)\n",
    "            torch.cuda.manual_seed_all(SEED)\n",
    "        \n",
    "        # Load a fresh model for this run\n",
    "        if model_a == 'MobileNetV2':\n",
    "            model_loaded = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "            image_size = [224, 224]\n",
    "        elif model_a == 'InceptionNetV3':\n",
    "            model_loaded = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "            image_size = [299, 299]\n",
    "        else:  # ResNet50\n",
    "            model_loaded = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            image_size = [224, 224]\n",
    "        \n",
    "        # Call model training with all the necessary parameters\n",
    "        model_train_evaluation(\n",
    "            data_in_folds=dataset['train_images'],\n",
    "            name=dataset['name'],\n",
    "            model_config=model_loaded,\n",
    "            img_size=image_size,\n",
    "            which_model=model_a\n",
    "        )\n",
    "        \n",
    "        print(f\"COMPLETED: {model_a} on {dataset['name']}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
